// Generated by dts-bundle v0.7.3
// Dependencies for this module:
//   ../../events
//   ../../firebase/app
//   ../../agora-rtc-sdk-ng

import { EventEmitter } from 'events';
import firebase from 'firebase/app';
import { ScreenSourceType } from 'agora-rtc-sdk-ng';

export class RTCDevices {
    videoDevices: MediaDeviceInfo[];
    audioInputDevices: MediaDeviceInfo[];
    audioOutputDevices: MediaDeviceInfo[];
}
export interface ITestVideoProfile {
    isEnabled: boolean;
    cameraId?: string;
    facingMode?: 'user' | 'environment';
    height?: number;
    width?: number;
    frameRate?: number;
}
export interface ITestAudioProfile {
    isEnabled: boolean;
    microphoneId?: string;
}
export interface ITestMediaProfile {
    videoProfile?: ITestVideoProfile;
    audioProfile?: ITestAudioProfile;
}
export interface IConferences {
    [confId: string]: {
        userId: string;
        conferenceObj: Conference;
    };
}
export interface IRemoteUserIdToConfIdMap {
    [userId: number]: string;
}
export interface IJoinMediaStatus {
    capturedMediaStatus: ILocalMediaStatus;
    publishedMediaStatus: IPublishedMediaStatus;
    callId: string;
}
export interface IAirmeetRTCClientConfig {
    airmeetClientId: string;
    airmeetAuthToken: string;
    isAutoLayout?: boolean;
}
export class UserIdManager {
    static fetchOriginalUserId(userId: any): any;
    static fetchOriginalScreenId(userId: any): string;
    static isScreenUserId(id: any): boolean;
}
export class AirmeetRTCClient extends EventEmitter {
    self: this;
    defInterceptLogLevel: string;
    defConsoleLogLevel: string;
    logInterceptorUrl: string;
    fetchChannelsAPIUrl: string;
    releasepubConferenceAPIUrl: string;
    AMSocketURl: string;
    fetchLastNActiveAPIUrl: string;
    pinUserApiUrl: string;
    airmeetClientId: string;
    conferences: IConferences;
    localUserIdtoConferenceMap: {
        [userId: string]: string;
    };
    rtcEventEmitter: RTCEventEmitter;
    airmeetLogLevel: number;
    baseConferenceId: string;
    baseUserId: string;
    baseConfParams: IConferenceParams;
    pubconferenceId: string;
    pubConference: Conference;
    subChannels: string[];
    pubUserId: string;
    harkAudioInit: boolean;
    speakingActivityInterval: any;
    audioAnalyser: any;
    lastASLReceivedTime: number;
    firebaseClient: FirebaseClient;
    accumulatedVoiceActivityAcrossConferences: any[];
    currentActiveSpeaker: any;
    localActiveSpeakersCount: number;
    layoutManager: LayoutManager;
    rtcStateManager: RTCStateManager;
    isAutoLayout: boolean;
    publishedMediaStatus: IPublishedMediaStatus;
    capturedMediaStatus: ILocalMediaStatus;
    audioAnalyserParams: IAudioAnalyserSetting;
    fbReferences: {
        ASLRef: any;
        publishingUserRef: any;
        channelAvailabilityRef: any;
    };
    interceptLog(logdata: any): void;
    constructor(config: IAirmeetRTCClientConfig);
    setLogInterceptor(logLevel: any, interceptor: any): void;
    setLogLevel(level: any): void;
    setActiveSpeakersCount: (localActiveSpeakersCount: any) => void;
    updateActiveSpeakersCount: (newActiveSpeakersCount: any) => Promise<void>;
    static getAvailableRTCDevices(): Promise<RTCDevices>;
    static captureTestStream(mediaProfiles: ITestMediaProfile): Promise<MediaStream>;
    static releaseTestStream(): void;
    checkCurrentCameraMicState(): void;
    checkScreenSharingCapability(): void;
    static attachMediaStream(stream: any, element: any): void;
    joinConference(confParams: IConferenceParams): Promise<IJoinMediaStatus>;
    joinChannels(confParams: IConferenceParams): Promise<IConferences>;
    join(): Promise<unknown>;
    initFirebaseConnection(baseUserId: any): Promise<void>;
    setupFirebaseListeners(): void;
    updateFirebaseDataonLeave(): void;
    resetFirebaseListeners(): void;
    captureLocalStream(mediaProfile: IMediaProfile): Promise<ILocalMediaStatus>;
    manageFBActiveSpeakerChangeEvent(allActiveSpeakers: any): void;
    checkAndEmitCurrentActiveSpeaker(activeSpeakers: any): void;
    manageFBNewSubChannelCreationEvent(newConfId: any): void;
    createAndJoinNewSubConference(newSubConfId: any): Promise<unknown>;
    getAllChannels(baseConfId: any): Promise<any>;
    fetchInternalPublishUserInfo(originalUserId: any): {
        internalUserId: any;
        remoteUserconfId: any;
    };
    getPublicationConference(): Conference;
    getConferenceInfo(): {
        conferenceId: string;
        userId: string;
        participantsCount: number;
        capturedMediaStatus: ILocalMediaStatus;
        publishedMediaStatus: IPublishedMediaStatus;
    };
    enableDualStream(isEnabled: boolean): Promise<void>;
    setStreamFallbackOption(userId: any, option: any): Promise<void>;
    renewToken(): Promise<void>;
    playLocalStream(mediaType: mediaTypes, videoElement?: HTMLElement): boolean;
    autoPlayRemoteStream(userId: any, mediaType: any, videoElement?: HTMLElement): boolean;
    playRemoteStream(userId: any, mediaType: any, videoElement?: any): boolean;
    playLocalCustomStream(videoElement?: HTMLElement): void;
    publishLocalStream(mediaType?: mediaTypes.AUDIO | mediaTypes.VIDEO): Promise<any>;
    updatePublication(mediaProfile: IMediaProfile): Promise<void>;
    unpublishLocalStream(mediaType?: string): Promise<void>;
    unpublishCustomLocalStream(mediaType?: string): Promise<void>;
    muteLocalVideo(isVideoOn: any): Promise<void>;
    muteLocalAudio(isAudioOn: any): Promise<void>;
    subscribeMedia(userId: any, mediaType: string, isInternalCall: any, element?: HTMLElement): Promise<void>;
    unsubscribeMedia(userId: any, mediaType: string, isInternalCall: any): Promise<void>;
    publishCustomLocalStream(mediaStream: any, config?: any): Promise<any>;
    shareScreen(screenProfile: IScreenProfile): Promise<void>;
    endScreenShare(): Promise<void>;
    setNewDeviceId(deviceType: any, deviceId: string): Promise<void>;
    getRTCStats(mediaType: any, sType: any, userId?: any): any;
    getActiverSpeakersList(): Promise<any>;
    getMyUserIds(): string[];
    getParticipantCount(): number;
    getParticipantsList(): Promise<any>;
    getConferenceCount(): number;
    cleanup(): Promise<void>;
    resetVars(): void;
    leave(): Promise<void>;
    close(): void;
    getConferenceByUserId(userId: number): any;
    logMyVoiceActivity(): void;
    setAudioAnalyserParams(params: IAudioAnalyserSetting): void;
    initAudioAnalyser(): void;
    startAudioAnalyser(): void;
    attachEventListeners(): void;
    pinUser(userId: any, pinType: pinTypes): Promise<void>;
    unpinUser(userId: any, pinType: pinTypes): Promise<void>;
    pinUserForAll(userId: any, isPinned: any): Promise<any>;
}

export interface IAudioAnalyserSetting {
    volumeThreshold: number;
    samplingInterval: number;
    sampleSize: number;
    positiveSampleThreshold: number;
    speechDurationThreshold: number;
    isAudioAnalyserLogsEnabled: boolean;
}
export interface IConferenceParams {
    conferenceId: string;
    mode: conferenceModes.LIVE | conferenceModes.RTC;
    myUserId: string;
    myRole: string;
    rtcProviderName?: string;
    appId?: string;
    prefVideoCodec?: string;
    extraLogArgs?: {
        [key: string]: string;
    };
    isAutoPublishEnabled?: boolean;
    mediaProfile: IMediaProfile;
    audioAnalyserParams?: IAudioAnalyserSetting;
}
interface IConference {
    mode: conferenceModes.LIVE | conferenceModes.RTC;
    conferenceId: String;
    prefVideoCodec: string;
    myUserId: string;
    myRole: string;
    adapterLoaded: boolean;
    rtcProviderName: string;
    appId: string;
    init: () => Promise<void>;
    setLogLevel: (level: number) => void;
    getConferenceManager: () => IConferenceManager;
    getStatsManager: () => IStatsManager;
    getStreamingManager: () => IStreamingManager;
}
export class Conference implements IConference {
    mode: conferenceModes.LIVE | conferenceModes.RTC;
    conferenceId: string;
    prefVideoCodec: string;
    adapter: IRTCAdapter;
    conferenceManager: ConferenceManager;
    statsManager: StatsManager;
    streamingManager: StreamingManager;
    conferenceToken: string;
    myUserId: string;
    myRole: string;
    adapterLoaded: boolean;
    rtcProviderName: string;
    appId: string;
    extraLogArgs: stringMap;
    constructor(confParams: IConferenceParams);
    init(): Promise<void>;
    join(): Promise<void>;
    setLogLevel(level: number): void;
    getConferenceManager(): ConferenceManager;
    getStatsManager(): StatsManager;
    getStreamingManager(): StreamingManager;
}
export {};

export default class RTCEventEmitter extends EventEmitter {
    static rtcEventEmitter: any;
    static getConferenceEmitter(): any;
}

import 'firebase/auth';
import 'firebase/database';
export default class FirebaseClient extends EventEmitter {
    static firebaseClient: FirebaseClient;
    firebaseApp: any;
    _emitter: EventEmitter;
    _dataRefs: {};
    _typeBaseData: {};
    db: any;
    static getInstance(baseUserId: any): Promise<any>;
    init(baseUserId: any): Promise<any>;
    fetchFirebaseToken(baseUserId: any): Promise<any>;
    getEmitter(): EventEmitter;
    ref(type: any, options?: {}): any;
    getDataRef(type: any, options?: {}): any;
    disconnect(): void;
    getDatabase(): typeof firebase.database;
}

export interface AdapterOptions {
    [key: string]: any;
}
export interface IVideoProfile {
    isEnabled: boolean;
    cameraId?: string;
    facingMode?: cameraMode.FRONT | cameraMode.REAR;
    optimisationMode?: streamOptimisationMode;
    minBitrate?: number;
    maxBitrate?: number;
    height?: number;
    width?: number;
    frameRate?: number;
    maxActiveSpeakers?: number;
}
export interface IAudioProfile {
    isEnabled: boolean;
    microphoneId?: string;
    AEC?: boolean;
    AGC?: boolean;
    ANS?: boolean;
    bitrate?: number;
    sampleRate?: number;
    sampleSize?: number;
    stereo?: boolean;
}
export interface IMediaProfile {
    video: IVideoProfile;
    audio: IAudioProfile;
}
export interface IScreenProfile {
    screenSourceType?: ScreenSourceType;
    optimizationMode?: streamOptimisationMode;
    minBitrate?: number;
    maxBitrate?: number;
    height?: number;
    width?: number;
    frameRate?: number;
}
export interface ISubscriptionOption {
    isVideoEnabled?: boolean;
    isAudioEnabled?: boolean;
}
export interface ICustomVideoConfig {
    maxVideoBitrate: number;
    minVideoBitrate: number;
    videoOptimizationMode: string;
    audioBitrate: number;
    audioSampleSize?: number;
    audioSampleRate?: number;
    audioStereo?: boolean;
}
export interface stringMap {
    [key: string]: string;
}
export interface ILocalMediaSettings {
    isAudioEnabled: boolean;
    isVideoEnabled: boolean;
}
export interface ILocalMediaStatus {
    isAudioEnabled: boolean;
    isVideoEnabled: boolean;
}
export interface IPublishedMediaStatus {
    isAudioPublished: boolean;
    isVideoPublished: boolean;
}
export interface IRTCAdapter {
    conferenceMode: string;
    prefCodec: string;
    init: (options: AdapterOptions) => Promise<void>;
    setLogLevel: (level: number) => void;
    checkBrowserCompatibility: () => Promise<boolean>;
    initClient: (appId: string, channelId: string, userId: string, role: string, mode: string, codec: string, extraLogArgs: stringMap) => any;
    getChannelToken: (channelId: string, userId?: string) => Promise<any>;
    joinChannel: (channelId: string, token: string, myUserId: string) => Promise<any>;
    setMediaProfile: (mediaProfile: IMediaProfile) => any;
    captureLocalStream: () => Promise<ILocalMediaStatus>;
    playLocalStream: (mediaType: mediaTypes, videoElement?: HTMLElement) => boolean;
    playRemoteStream: (userId: any, mediaType: any, videoElement: any) => boolean;
    playLocalCustomStream: (videoElement?: HTMLElement) => boolean;
    publishLocalStream: (mediaType?: mediaTypes.VIDEO | mediaTypes.AUDIO) => Promise<any>;
    publishCustomLocalStream: (mediaStream: MediaStream, config?: ICustomVideoConfig) => Promise<void>;
    unpublishLocalStream: (mediaType?: string) => Promise<void>;
    unpublishCustomLocalStream: (mediaType?: string) => Promise<void>;
    subscribeMedia: (userId: string, mediaType: string, videoElement?: HTMLElement) => Promise<void>;
    unsubscribeMedia: (userId: string, mediaType: string) => Promise<void>;
    getCurrentLocalStream: () => MediaStream;
    leave: () => Promise<void>;
    updatePublication: (mediaProfile: IMediaProfile) => Promise<void>;
    muteLocalAudio: (videoProfile: IVideoProfile) => Promise<void>;
    muteLocalVideo: (audioProfile: IAudioProfile) => Promise<void>;
    shareScreen: (screenProfile: IScreenProfile) => Promise<any>;
    endScreenShare: () => Promise<void>;
    setNewDeviceId: (deviceType: 'camera' | 'mic', deviceId: string) => Promise<void>;
    getRTCStats: (mediaType: mediaTypes.VIDEO | mediaTypes.AUDIO, userType: 'local' | 'remote', userId?: string) => any;
    toggleRemoteUserVideo: (userId: string, isVideoOn: boolean, videoElement: HTMLVideoElement) => Promise<void>;
    setupStreaming: (users: string[]) => Promise<void>;
    startStreaming: (rtmpUrl: string) => Promise<void>;
    stopStreaming: (rtmpUrl: string) => Promise<void>;
    enableDualStream: (isEnabled: boolean) => Promise<void>;
    setStreamFallbackOption: (userId: string, option: 1 | 2) => Promise<void>;
    renewToken: () => Promise<void>;
    getParticipantsList: () => Array<string>;
}

export const enum conferenceModes {
    LIVE = "live",
    RTC = "rtc"
}
export const enum videoCodecs {
    H264 = "h264",
    VP8 = "vp8",
    VP9 = "vp9"
}
export const enum cameraMode {
    FRONT = "user",
    REAR = "environment"
}
export const enum streamOptimisationMode {
    DETAIL = "detail",
    MOTION = "motion"
}
export const enum screenSourceType {
    SCREEN = "screen",
    WINDOW = "window",
    APPLICATION = "application"
}
export const enum mediaTypes {
    AUDIO = "audio",
    VIDEO = "video",
    SCREEN = "screen"
}
export const enum pinTypes {
    FOR_ALL = "for_all",
    FOR_ME = "for_me"
}
export const enum statsType {
    LOCAL = "local",
    REMOTE = "remote"
}
export const enum RTCEntity {
    SCREEN = "screen",
    PUBLICATION = "publication",
    SUBSCRIPTION = "subscription",
    JOINCONFERENCE = "join",
    LEAVE = "leave"
}
export const enum screenStates {
    INACTIVE = 0,
    ACTIVATING = 1,
    DEACTIVATING = 2,
    ACTIVE = 4
}
export const enum joinStates {
    NOT_JOINED = 0,
    JOINING = 1,
    JOINED = 2
}
export const enum publishStates {
    NOT_PUBLISHED = 0,
    PUBLISHING = 1,
    PUBLISHED = 2
}
export const enum subscribeStates {
    NOT_SUBSCRIBED = 0,
    SUBSCRIBING = 1,
    SUBSCRIBED = 2
}
export const enum captureStreamStates {
    NOT_CAPTURED = 0,
    CAPTURING = 1,
    CAPTURED = 2
}
export const enum leaveStates {
    NOT_LEFT = 0,
    LEAVING = 1,
    LEFT = 2
}

interface IRemoteUserInfo {
    isRendered: boolean;
    isPublisher: boolean;
    isVideoPaused: boolean;
    isAudioMuted: boolean;
    originalUserId: string;
    conferenceId: string;
}
interface IRemoteUserInfoList {
    [userId: string]: IRemoteUserInfo;
}
interface IRemoteUsersMarker {
    max: number;
    count: number;
    rendered: number;
}
export class LayoutManager {
    isSideLayoutActive: boolean;
    remoteUsersMarker: IRemoteUsersMarker;
    remoteUsersInfoList: IRemoteUserInfoList;
    isRenderingNewUserInProcess: boolean;
    renderedUsersSet: Set<unknown>;
    airmeetRTCClient: AirmeetRTCClient;
    localUserId: string;
    isAutoLayout: boolean;
    static layoutManager: LayoutManager;
    OriginalToInternalRemoteUserIdMap: {};
    cleanup(): void;
    static getInstance(airmeetRTCClient: AirmeetRTCClient): LayoutManager;
    updateMaxSpeakers(maxActiveSpeakers: any): void;
    addLocalVideoPlaceholder(): void;
    formatActiveSpeakers(activeSpeakers: any, myUserIds: any, localActiveSpeakersCount: any, renderedUsersSet: any): {
        newUsers: any[];
        usersToRemove: any[];
    };
    manageNewActiveUsersList(lastNActiveSpeakers: any): void;
    resuffleVideoViews(newSpeakers: any, speakersToRemove: any): Promise<void>;
    addNewSpeakerToView(newSpeakerId: any): Promise<void>;
    removeSpeakerFromView(oldSpeakerId: any, shallRemoveSlot: any): Promise<void>;
    replaceSpeaker(newSpeaker: any, oldSpeaker: any): Promise<void>;
    manageViewOnRemoteTrackPublished(userId: any, mediaType: any): Promise<unknown>;
    subscribeUnpausedVideoAndFireEvent(userId: any): Promise<unknown>;
    manageViewOnRemoteTrackUnpublished(userId: any, mediaType: any): void;
    manageViewPostRemoteUserJoin(userData: any): Promise<void>;
    manageViewPostRemoteUserLeave(userData: any): void;
    reserveSlotElement(participantId: any): HTMLVideoElement;
    addSlot(participantId: string): void;
    removeSlot(userId: string): void;
    clearSlot(userId: string): void;
    updateRenderInfo(participantId: any): void;
    updateLayout(): void;
    updateLayoutClass(newClassNames: any): void;
    getLocalVideoElement(): HTMLElement;
    /******************************************************************************************/
    addScreenVideoandUpdateLayout(userId: string): Promise<void>;
    removeScreenVideoandUpdateLayout(userId: string): void;
    changeToSideLayout(): void;
}
export {};

export class RTCStateManager {
    rtcStates: {
        screen: {
            prevState: any;
            currentState: screenStates;
        };
        publication: {
            prevState: any;
            currentState: publishStates;
        };
    };
    setState(entity: any, newState: any): void;
    getState(entity: any): any;
    resetRTCStates(): void;
}

export class ConferenceManager extends EventEmitter implements IConferenceManager {
    adapter: IRTCAdapter;
    rtcEventEmitter: RTCEventEmitter;
    confName: string;
    constructor(confName: any, adapter: IRTCAdapter);
    setMediaProfile(mediaProfile: IMediaProfile): void;
    captureLocalStream(): Promise<import("../adapters/IRTCAdapter").ILocalMediaStatus>;
    playLocalStream(mediaType: any, videoElement?: HTMLElement): boolean;
    playRemoteStream(userId: any, mediaType: any, videoElement?: HTMLElement): boolean;
    playLocalCustomStream(videoElement?: HTMLElement): boolean;
    publishLocalStream(mediaType?: mediaTypes.AUDIO | mediaTypes.VIDEO): Promise<any>;
    publishCustomLocalStream(mediaStream: any, config?: ICustomVideoConfig): Promise<void>;
    unpublishLocalStream(mediaType: string): Promise<void>;
    unpublishCustomLocalStream(mediaType: string): Promise<void>;
    subscribeMedia(userId: any, mediaType: string, element?: HTMLElement): Promise<void>;
    leave(): Promise<void>;
    updatePublication(mediaProfile: IMediaProfile): Promise<void>;
    unsubscribeMedia(userId: string, mediaType: string): Promise<void>;
    getCurrentLocalStream(): MediaStream;
    setNewDeviceId(deviceType: any, deviceId: string): Promise<void>;
    muteLocalVideo(isVideoOn: boolean): Promise<void>;
    muteLocalAudio(isAudioOn: boolean): Promise<void>;
    shareScreen(screenProfile: IScreenProfile): Promise<any>;
    endScreenShare(): Promise<void>;
    toggleRemoteUserVideo(userId: any, isVideoOn: any, videoElement: any): Promise<void>;
    enableDualStream(isEnabled: any): Promise<void>;
    setStreamFallbackOption(userId: any, option: any): Promise<void>;
    renewToken(): Promise<void>;
    getParticipantsList(): string[];
}

export class StatsManager extends EventEmitter implements IStatsManager {
    adapter: IRTCAdapter;
    rtcEventEmitter: RTCEventEmitter;
    confName: string;
    constructor(confName: any, adapter: IRTCAdapter);
    getRTCStats(mediaType: mediaTypes.AUDIO | mediaTypes.VIDEO, userType: statsType.LOCAL | statsType.REMOTE, userId?: string): any;
}

export class StreamingManager {
    adapter: IRTCAdapter;
    constructor(adapter: IRTCAdapter);
    setupStreaming(users: any): Promise<void>;
    startStreaming(rtmpUrl: any): Promise<void>;
    stopStreaming(rtmpUrl: any): Promise<void>;
}

export interface IConferenceManager {
        adapter: IRTCAdapter;
        rtcEventEmitter: RTCEventEmitter;
        /**
            * sets profile for Audio and Video tracks which needs to be captured and published.
            * > This methods just set the profile without actually capturing and publishing the stream, which is actually done via separate {@link captureLocalStream} and {@link publishLocalStream} methods
            *
            * @param mediaProfile Audio and Video profile for the tracks to be captured
            * @category Local Track
            */
        setMediaProfile: (mediaProfile: IMediaProfile) => void;
        /**
            * Captures the local tracks from camera and microphone, based on the media profile set via {@link setMediaProfile} method.
            * > If this methoid is called without calling {@link setMediaProfile} method, then the default profile is assumed.
            *
            * @category Local Track
            */
        captureLocalStream: () => Promise<ILocalMediaStatus>;
        /** Plays the local media tracks (Audio and/or Video based on what has been captured via {@link captureLocalStream} method) on the web page.
            *
            * @param videoElement Specifies a DOM element. The SDK will create a `<video>` element under the specified DOM element to play the video track. In order to play audio track, no need to pass any element.
            */
        playLocalStream: (mediaType: mediaTypes, videoElement?: HTMLElement) => boolean;
        playRemoteStream: (userId: string, mediaType: 'audio' | 'video', videoElement?: HTMLElement) => boolean;
        /**
            * Publishes the local audio and/or video tracks to a channel, which has already been captured via {@link captureLocalStream} method
            *
            * If the video track has been published, the [AirmeetRTCClient.on("remote-video-track-published")]{@link } callback is triggered on the remote client.
            * If the Audio track has been published, the [AirmeetRTCClient.on("remote-audio-track-published")]{@link } callback is triggered on the remote client.

            * > Note:
            * > - An `AirmeetRTCClient` object can publish multiple audio tracks but only one video track. The SDK automatically mixes the audio tracks into one audio track.
            * > - Safari does not support publishing multiple audio tracks on versions earlier than Safari 12.
            * @param mediaType The media type of the tracks to publish
            * - `"video"`: Publish the video track only.
            * - `“audio”`: Publish the audio track only.
            * -  `"undefined"` : Publish both the Audio and Video Tracks
            * @category Airmeet Core
            */
        publishLocalStream: (mediaType: 'audio' | 'video') => Promise<void>;
        /**
            * Publishes a custom MediaStream (with both Audio and Video track) to a channel. A MediaStream can be created out of a local Audio/Video by using browser's captureStream() API after
            * playing the media over an HTML5 Video tag or a canvas
            *
            * Once the custom video track has been published, the [AirmeetRTCClient.on("remote-video-track-published")]{@link } callback is triggered on the remote client.
            * Once the custom Audio track has been published, the [AirmeetRTCClient.on("remote-audio-track-published")]{@link } callback is triggered on the remote client.

            * > Note:
            * > - An `AirmeetRTCClient` object can publish multiple audio tracks but only one video track. The SDK automatically mixes the audio tracks into one audio track.
            * > - Safari does not support publishing multiple audio tracks on versions earlier than Safari 12.
            * @category Airmeet Core
            */
        publishCustomLocalStream: (mediaStream: MediaStream, config?: ICustomVideoConfig) => Promise<void>;
        /**
            * Unpublishes the local audio or video tracks based on the parameter 'mediaType'. If no parameter is passed, both the tracks are unpublished
            *
            * After the local client unpublishes, the [AirmeetRTCClient.on("user-unpublished")]{@link } callback is triggered on each remote client in the channel.
            *
            * @category Airmeet Core
            */
        unpublishLocalStream: (mediaType: 'audio' | 'video') => Promise<void>;
        unpublishCustomLocalStream: (mediaType: 'audio' | 'video') => Promise<void>;
        /**
            * Subscribes to the audio or video track of a remote user based on the parameter provided and plays it on the provided DOM element.
            *
            * @param userId userId of the remote user.
            * @param mediaType The media type of the tracks to subscribe to.
            * - `"video"`: Subscribe to the video track only.
            * - `“audio”`: Subscribe to the audio track only.
            * @param videoElement Specifies a DOM element to play video. The SDK will create a `<video>` element under the specified DOM element to play the video track.
            * > However this parameter can be skipped if only the audio track needs to be subscribed and played.
            * @returns When the subscription succeeds, the subscribed track is automaticalled played in the provided DOM element.
            * > The `Promise` object throws the `TRACK_IS_NOT_PUBLISHED` error if the specified tracks do not exist.
            * @category Airmeet Core
            */
        subscribeMedia: (userId: any, mediaType: string, element?: HTMLElement) => Promise<void>;
        /**
            * Unsubscribes from the audio and/or tracks of a remote user.
            *
            * @param userId The remote user.
            * @param mediaType The media type of the tracks to unsubscribe from:
            * - `"video"`: Unsubscribe from the video track only.
            * - `“audio”`: Unsubscribe from the audio track only.
            * - empty: Unsubscribe from all the tracks published by the remote user.
            * @returns The `Promise` object throws the `TRACK_IS_NOT_SUBSCRIBED` error if the specified tracks do not exist.
            * @category Airmeet Core
            */
        unsubscribeMedia: (userId: string, mediaType: string) => Promise<void>;
        getCurrentLocalStream: () => MediaStream;
        /**
            * Leaves a channel.
            *
            * When a user (in the communication profile) or a host (in the live-broadcast profile) leaves the channel, the [AirmeetRTCClient.on("user-left")]{@link } callback is triggered on each remote client in the channel.
            * @category Airmeet Core
            */
        leave: () => Promise<void>;
        /**
            * Updates the publication profile for the outgoing stream on-the-fly.
            * > Currently profile for only video track can be updated post-publication, where as audio profile cannot be changed once published.
            *
            * @param mediaProfile new video profile/configuration with which the local video should be published.
            * @category Airmeet Core
            */
        updatePublication: (mediaProfile: IMediaProfile) => Promise<void>;
        /**
            * Updates the local track based on the new device selection on-the-fly.
            *
            * @param deviceType It takes one of these - "camera" | "mic" | "audioOutput"
            * @param deviceId Id of the new device selected
            * @category Airmeet Core
            */
        setNewDeviceId: (deviceType: 'camera' | 'mic' | 'audioOutput', deviceId: string) => Promise<void>;
        /**
            * Update the media profile of the published Track.
            *
            * @param isVideoOn boolean value based on which the published video track will be turned on or off. Setting this parameter 'true' will turn on/Unpause the video where as 'false' will turn off/Pause the video.
            * @category Airmeet Core
            */
        muteLocalVideo: (isVideoOn: boolean) => Promise<void>;
        /**
            * Mute/Unmute the published Audio Track.
            *
            * @param isAudioOn boolean value based on which the published Audio track will be turned on or off. Setting this parameter 'true' will unmute the Audio where as 'false' will mute the Audio for all the subscribers.
            * @category Airmeet Core
            */
        muteLocalAudio: (isAudioOn: boolean) => Promise<void>;
        /**
            * initiates the screen sharing by capturing the local streama nd publishing it for other remote users
            *
            * @category Airmeet Track
            */
        shareScreen: (screenProfile: IScreenProfile) => Promise<any>;
        /**
            * Turns off the screen sharing
            *
            * @category Airmeet Track
            */
        endScreenShare: () => Promise<void>;
        enableDualStream: (isEnabled: boolean) => Promise<void>;
        setStreamFallbackOption: (userId: string, option: 1 | 2) => Promise<void>;
        renewToken: () => Promise<void>;
        getParticipantsList: () => string[];
}

export interface IStreamingManager {
        /**
            * sets profile for RTMP streaming
            *
            * @param users array of users whose streams needs to be composited for the RTMP streaming
            * @category Streaming
            */
        setupStreaming: (users: string[]) => Promise<void>;
        /**
            * starts RTMP streaming
            *
            * @param rtmpUrl RTMP endpoint url where the RTMP output stream needs to be pushed
            * @category Streaming
            */
        startStreaming: (rtmpUrl: string) => Promise<void>;
        /**
            * stops RTMP streaming
            *
            * @param rtmpUrl RTMP endpoint url where the RTMP output stream needs to be stopped
            * @category Streaming
            */
        stopStreaming: (rtmpUrl: string) => Promise<void>;
}

export interface IStatsManager {
    /**
      * fetches Media Statistics of various Mdedia stream, both local and remote
      *
      * @param mediaType media for which stats needs to be fetched. possible values - "audio"/"video"
      * @param userType possible values - "local"/"remote"
      * @param userId required for remote users, not for own local stream
      * @category Statistics
      */
    getRTCStats(mediaType: 'audio' | 'video', userType: 'local' | 'remote', userId?: string): any;
}

